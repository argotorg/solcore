\documentclass[a4paper, 11pt]{article}
\usepackage[top=3cm, bottom=3cm, left=2cm, right=2cm]{geometry} 
\geometry{a4paper} 
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{graphicx} 
\usepackage{amsmath,amssymb,amsfonts,amsthm}  
\usepackage{bm}  
\usepackage[pdftex,bookmarks,colorlinks,breaklinks]{hyperref}  
\usepackage{memhfixc} 
\usepackage{pdfsync}  
\usepackage{fancyhdr}
\usepackage{float} 
\usepackage{proof}
\usepackage{listings}
\pagestyle{fancy}

\title{Specification for the new Solidity Language}
\author{The Argot Collective}
%\date{}

\begin{document}
\maketitle
%\tableofcontents

\lstdefinelanguage{solidity}{
  keywords={function, forall, data, class, instance, match, return, contract},
}
\lstset{
  language=solidity,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries,
}

%\lstset{language=solidity} 

%%%%%%%%%%% Macros %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\word}{\ensuremath{\mathtt{word}}}
\newcommand{\unit}{\ensuremath{\mathtt{unit}}}
\newcommand{\typing}[1]{\ensuremath{\overset{\text{\tiny{#1}}}{\vdash}}}
\newcommand{\cc}{\ensuremath{\overset{\text{cc}}}{\leadsto}}
\newcommand{\inst}{\ensuremath{\sqsubseteq}}
\newcommand{\invoke}{\ensuremath{\mathtt{Invokable.invoke}}}
\newcommand{\invokable}{\ensuremath{\mathtt{Invokable}}}
\newcommand{\dom}[1]{\ensuremath{\mathtt{dom}(#1)}}
\newcommand{\id}{\ensuremath{\mathtt{id}}}
\newcommand{\ftv}{\ensuremath{\mathtt{ftv}}}
\newcommand{\fpv}{\ensuremath{\mathtt{fpv}}} 
\newcommand{\closuretype}{\ensuremath{\overset{\tiny{ctype}}{\leadsto}}}
\newcommand{\sig}{\ensuremath{\overset{\tiny{sig}}{\leadsto}}}
\newcommand{\unique}{\ensuremath{\overset{\tiny{unique}}{\leadsto}}}
\newcommand{\geninvoke}{\ensuremath{\overset{\tiny{gen}}{\leadsto}}}
\newcommand{\sats}[3]{\Theta ; #3 \vdash^{\mathtt{sats}} #1 \leadsto #2}
\newcommand{\mgu}{\ensuremath{\mathtt{mgu}}}
\newcommand{\reduce}{\vdash^{\mathtt{red}}}
\newcommand{\simp}{\vdash^{\mathtt{simp}}}
\newcommand{\impr}{\vdash^{\mathtt{impr}}}
\newcommand{\solidity}{new Solidity } 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}\label{sec:introduction}

In this report we describe the abstract syntax, 
the type system and desugaring steps for a new 
version of the \solidity programming language.

\section{Language overview} 

Before diving into the formalization details, it 
is useful to explain how the new language will look like 
and the steps which will be formally defined in this 
report. Let's consider the following simple code 
piece which defines three functions inside a contract:

\begin{lstlisting}[language=solidity]
contract Ex {
  function id () {
    return lam(x) {return x ;};
  }
  function compose(f,g) {
    return lam(x){ return f(g(x));};
  }
  function main () {
    let f = compose(id,id);
    return f(42);
  }
}
\end{lstlisting}

In this short example we can see some features of the \solidity 
language: it will have anonymous functions and 
function arguments and return types can be omitted because 
the language will have type inference. The same code 
example can be written using type annotations as follows:

\begin{lstlisting}[language=solidity]
contract Ex {
  forall a . function id () -> a -> a {
    return lam(x) {return x ;};
  }
  forall a b c . function compose(f : b -> c, g : a -> b) : a -> c {
    return lam(x){ return f(g(x));};
  }
  function main () -> word {
    let f : a -> a = compose(id,id);
    return f(42);
  }
}
\end{lstlisting}

While we can understand the typing of functions as in the previous
code piece, the \solidity compiler will produce an equivalent 
code using the primitive $\invokable$ type class. 

\begin{lstlisting}[language=solidity]
class self : Invokable (argsTy, retTy) {
  function invoke (a : self, args : argsTy) -> retTy ;
}
\end{lstlisting}
which call a function using the arguments $args : argsTy$. The compiler 
uses the $\invokable$ class to deal with high-order functions. The 
strategy is to generate a type for each defined function and a 
instance of the $\invokable$ class for each function using as main 
type argument a generated \emph{unique type} for the function. 
Unique types have just one constructor with no arguments. Considering 
functions \texttt{id}, \texttt{compose} and \texttt{main}; the compiler 
will generate the following unique type definitions:

\begin{lstlisting}[language=solidity]
data t_id0(args,ret) = t_id0 
data t_compose1 (args, ret) = t_compose1
data t_main2 (args, ret) = t_main2 
\end{lstlisting}
Another transformation step is to perform closure conversion on 
anonymous functions. The function \texttt{id} is compiled to 
the following equivalent code snippet:

\begin{lstlisting}
forall a . function id () -> t_lambda34(a,a) {
  return t_lambda34;
}
data t_lambda34(args, ret) = t_lambda34
forall a . instance t_id0((),t_lambda34(a,a)) : Invokable((),t_lambda34(a,a)) {
  function invoke (self : t_id((),t_lambda34(a,a)), x : ()) -> t_lambda34(a,a) {
    return id() ;
  }
}
forall a . function lambda3 (x : a) -> a {
  return x ; 
}
forall a. instance t_lambda34(a,a) : Invokable (a, a) {
  function invoke (self : t_lambda34(a,a), x : a) -> a {
    return x;
  }
}
\end{lstlisting}
Since the $\lambda$-abstract present in \texttt{id} definition does 
not have captures, we can just lift its body into a 
new function and produce its corresponding unique type 
and $\invokable$ instance. Notice, that \texttt{id}'s 
body now produces the constructor of its unique type 
which is used to guide instance search to find the 
correct to called by $\invoke$.

Next listing deals with the desugared version for function 
\texttt{compose}, which has free variables in its 
$\lambda$-expression. We then define a type for representing 
its closure and define a $\invokable$ instance using the 
closure type as its main argument type. The resulting 
desugared code for compose is as follows:

\begin{lstlisting}
// lam(x) { return f(g(x));}
data t_closure4(a,b,c,d,e) = t_closure4(d,e) 
forall e : Invokable(b,c), 
       d : Invokable(a,b) . t_closure4(a,b,c,d,e) : Invokable (a, c) { 
  function lambda5(env : t_closure4(a,b,c,d,e), x : a) -> c {
    match env {
    | tclosure4(f,g) => 
      Invokable.invoke(f, Invokable.invoke(g, x));
    };
  }
}
forall a b c d e. function compose(f : d, g : e) -> t_closure4(a,b,c,d,e) {
  return t_closure4(f,g);
}
\end{lstlisting}

The last step of the desugared code is for the \texttt{main} function, which 
is presented next. Notice that the indirect call for function reference 
\texttt{f} is desugared to a call to $\invoke$ in which \texttt{f} is 
passed as the argument of the called instance main type.

\begin{lstlisting}
function main () -> word {
  let f = compose(t_id0, t_id0);
  return Invokable.invoke(f,42);
}
\end{lstlisting}


\section{Notations used}\label{sec:notations} 

We start by defining some notations used in the 
source language abstract syntax. As usual, all 
meta-variables can appear primed or subscripted. 
We let $[x]$ denote an optional occurrence of $x$ and 
$\overline{x}$ a sequence of $x$'s.

\begin{table}[H]
  \begin{tabular}{|c|l|} 
    \hline 
    Meta-variable & Meaning \\
    \hline 
    $Q$        & Qualified name \\ 
    $C$        & Type class name\\
    $X$        & Contract name\\ 
    $T$        & Type constructor name\\
    $D$        & Algebraic data type constructor name\\
    $f$        & Function name\\ 
    $I$        & EVM instruction\\
    $v$        & Variable name \\
    $w$        & Word literal \\
    \hline
  \end{tabular}
  \centering
  \caption{Meta-variable usage.}
\end{table}

In the following sections, we define inference rules to 
formalize typing and desugaring of source programs. 
The general form of inference judgements are 

\[
  environments \overset{\text{judgment name}}{\vdash} source \leadsto target : moreinfo
\]

where $environments$ contain various contextual information, $target$ is 
the translation result of $source$ program and $moreinfo$ is some 
additional result produce by the rule (e.g. if the $source$ is an 
expression, $moreinfo$ is its type).
An environment is a finite map between names and some relevant 
information. We use different meta-variables to denote different 
types of environments.
We allow ourselves a bit of informality and use 
set operations on finite maps with their obvious meanings.
Additionally, we use the following notations over finite maps:

\begin{itemize}
  \item Notation $v \mapsto value$ denotes a map entry with 
    key $v$ and associated $value$ and $E[v\mapsto value]$ denotes 
    the insert / update operation of key $v$ for the 
    map $E$.
  \item $\dom{E_1} = \{name\,|\,name : info \in E_1\}$ defines the 
    domain, i.e. set of names, defined on the environment.
  \item $E(v) = r$ denotes the finite map lookup operation. 
    \[
      \begin{array}{lcl}
        E(v) & = & \left\{
                     \begin{array}{ll}
                       value & \mathtt{when }\:[v \mapsto value] \in E\\
                       \bot  & \mathtt{otherwise}\\
                     \end{array}
                   \right. 
      \end{array}
    \]
\end{itemize}

Our formalization will use the following environments:

\begin{itemize}
  \item $\Theta$: global definition environment, which is formed by the 
    following environments:
    \begin{itemize}
      \item $\Theta_U$: environment associating function names to 
        its respective unique data type definitions.
      \item $\Theta_X$: environment associating contract names to 
        a environment containing its field names and its respective 
        types.
      \item $\Theta_C$: environment associating class names to 
        a pair formed by the class declaration itself and a 
        list of its defined instances. We let $\Theta[C \mapsto^i instdecl]$ 
        denote the operation of including a new instance declaration 
        for class $C$ in $\Theta_C$.
    \end{itemize}
  \item $\Gamma$: typing environment, which holds definitions of 
        defined variables in scope, data constructors and 
        function definitions. Following common practice, 
        notation $\Gamma, x : \sigma$ denotes the inclusion 
        of the assumption $x : \sigma$ in $\Gamma$.
\end{itemize}


\section{Source language abstract syntax}\label{sec:source-abstract-syntax}

\begin{figure}[H] 
  \begin{tabular}{rcl}
    $mod \in $ Module & $\to$ & $imp_1$ ; ... ; $imp_n;$ $decl_1$; ...; $decl_m$\\
    $imp \in$ Import & $\to$ & \texttt{import} $Q$; \\
    $decl \in$ Declaration & $\to$ & $classdecl$ $|$ $instdecl$ $|$ $datadecl$ $|$ $fundecl$ $|$ $contract$ \\
    $classdecl$ $\in$ Class & $\to$ & $\forall$ $\alpha_1$ ... $\alpha_n$ $P$ $.$ \texttt{class} $\alpha$ : $C$($\alpha_1$, ..., $\alpha_n$) $sig_1$; ... ; $sig_k$ \\  
    $instdecl$ $\in$ Instance & $\to$ & $\forall$ $\alpha_1$ ... $\alpha_n$ $P$ $.$ \texttt{instance} $\tau$ : C($\tau_1$, ... , $\tau_m$) $fundecl_1$ ; ... ; $fundecl_k$ \\ 
    $datadecl$ $\in$ Data Type & $\to$ & \texttt{data} $T$($\alpha_1$,...,$\alpha_n$) \texttt{=} $dconstr_1$ ... $dconstr_m$\\
    $fundecl$ $\in$ Function & $\to$ & $sig$ $body$ \\
    $contract$ $\in$ Contract & $\to$ & \texttt{contract} $X$($\alpha_1$, ... , $\alpha_n$) $cdecl_1$ ;...; $cdecl_m$ \\
    $P$ $\in$ Context & $\to$ & $\pi_1$ ... $\pi_n$ \\ 
    $sig$ $\in$ Signature & $\to$ & $\forall$ $\alpha_1$ ... $\alpha_n$ $P$ $.$ \texttt{function} $f$ ($arg_1$,..., $arg_m$) $[\to\tau]$\\ 
    $dconstr$ $\in$ Data Constr. & $\to$ & $D$($\tau_1$,...,$\tau_n$)\\
    $body$ $\in$ Function body & $\to$ & $stmt_1$ ... $stmt_n$\\ 
    $cdecl$ $\in$ Contract Decl. & $\to$ & $constr$ $|$ $fundecl$ $|$ $fielddecl$\\
    $pi$ $\in$ Predicate & $\to$ & $\tau$ $:$ $C$($\tau_1$,...,$\tau_n$)\\
    $arg$ $\in$ Argument & $\to$ & $v [:\tau]$\\
    $constr$ $\in$ Contract Constr. & $\to$ & \texttt{constructor} ($arg_1$, ..., $arg_n$) $body$ \\ 
    $fielddecl$ $\in$ Field Decl. & $\to$ & $\tau$ $v$ $[=\,e]$\\ 
    $stmt$ $\in$ Statement & $\to$ & \texttt{let} $[\tau]$ $v$ $[=\:e]$ $|$ $lvalue$ $=$ $e$ $|$ $e$ $|$ \texttt{return} $e$\\ 
                     & $|$ &  $match$ $|$ \texttt{assembly} $asm$\\
    $e$ $\in$ Expr. & $\to$ & $w$ $|$ $v$ $|$ $D(e_1,...,e_n)$ $|$ $e.v$ $|$ \texttt{lam}$(arg_1,...,arg_n)$ $body$ \\ 
                 & $|$ & $f(e_1,...,e_n)$ $|$ $e : \sigma$\\
    $match$ $\in$ Match & $\to$ & \texttt{match} $e_1$, ..., $e_n$ \texttt{with} $eqn_1$, ..., $eqn_m$\\
    $asm$ $\in$ Assembly & $\to$ & $\{ystmt_1$ ; ... ; $ystmt_n\}$\\ 
    $eqn$ $\in$ Equation & $\to$ & $(pat_1,...,pat_n)$ \texttt{=>} $body$\\ 
    $pat$ $\in$ Pattern & $\to$ & $w$ $|$ $v$ $|$ $D(pat_1,...,pat_n)$ $|$ $\_$ \\
    $ystmt$ $\in$ Yul Stmt. & $\to$ & $v$ $=$ $yexp$ $|$ \texttt{let} $v$ $[=yexp]$ $|$ $yexp$ $|$ $\{ystmt_1;...;ystmt_n\}$ $|$ \texttt{if} $e$ $asm$\\
                      & $|$ & \texttt{for} $asm$ $yexp$ $asm$ $asm$ $|$ \texttt{switch} $yexp$ $\{case_1 ; ... ; case_n $ $[default]\}$\\
    $yexp$ $\in$ Yul Exp. & $\to$ & $w$ $|$ $v$ $|$ $I(yexp_1, ..., yexp_n)$\\
    $case$ $\in$ Case & $\to$ & $w$ \texttt{=>} $asm$ \\
    $default$ $\in$ Def. Case & $\to$ & \texttt{default} $asm$\\ 
 \end{tabular}
  \centering
  \caption{New Solidity surface abstract syntax}
\end{figure}

\section{Type syntax}

The type syntax is defined by Figure~\ref{fig:typesyntax}. 

\begin{figure}[H] 
  \begin{tabular}{rcl}
    $\tau$ $\in$ Type & $\to$ & $\alpha$ $|$ $T$($\tau_1$,...,$\tau_n$)\\
    $\rho$ $\in$ Qual. Type & $\to$ & $P$ $\Rightarrow$ $\tau$\\ 
    $\sigma$ $\in$ Scheme & $\to$ & $\forall$ $\overline{\alpha}$ $.$ $\rho$\\
  \end{tabular}
  \centering 
  \caption{Type syntax}
  \label{fig:typesyntax}
\end{figure}


Simple types ($\tau$) are either type variables, represented by 
meta-variable $\alpha$, or fully-applied type 
constructors\footnote{We use this restriction on type constructors to avoid 
checking kinds.}.
We let meta-variable $T$ denote an arbitrary type constructor and we assume 
the existence of the following primitive type constructors:

\begin{itemize}
  \item $\word$: primitive type for UInt256 literals.
  \item $\unit$: type which has a unique inhabitant. We denote both the 
    unit type and its element by $()$.
  \item $\mathtt{arrow}$: function type constructor, written as right 
    associative infix operator as $\tau_1\to\tau_2$. Sometimes we 
    write $n$-ary arrows in curried form as a syntax sugar to its 
    uncurryied version.
    \[ 
      \tau_1 \times ... \times \tau_{n - 1} \to \tau_n = \tau_1 \to ... \to \tau_{n - 1} \to \tau_n
    \]
  \item $\mathtt{tuples}$: We assume the existence of $n$-ary tuples ($n\geq 2$),
    which are translated internally into right-nested pairs.
\end{itemize}

A qualified type ($\rho$) is formed by a set of 
type class predicates, denoted by $P$, and a 
simple type. We let meta-variable $\pi$ be any predicate. 
Notation $P,Q$ denote the union of the predicate sets, $P\cup Q$.
A type scheme ($\sigma$) is qualified type 
which has a set of quantified type variables.
Notation $\ftv(\sigma)$ denotes the set of $\sigma$'s free type variables.
We slighly abuse notation by using $ftv$ for typing context 
and environments with its obvious definition. We let $\fpv(x)$ denote 
the set of $x$'s free program variables. A \emph{substitution} is a 
finite function associating type variables 
to simple types. We let meta-variable $S$ denote an arbitrary 
substitution. Notation $[\overline{\alpha \mapsto \tau}]$ 
denotes the substitution that replaces type variables $\overline{\alpha}$
by the types $\overline{\tau}$, $\id$ denotes the identity substitution 
and $S_1 \circ S_2$ denotes the composition of $S_1$ and $S_2$.
Application of a substition $S$ to a type $\tau$ is denoted by $S\,\tau$ and 
application is extended to constraints and qualified types as 
expected. Given two types, $\tau_1$ and $\tau_2$, we let 
$\mgu(\tau_1,\tau_2)$ denote the most general unifier for these types. 
We extend $\mgu$ to constraints and qualified types as usual.
Finally, given a substitution $S$ and a set of type variables 
$V$, notatation $S\,|_{V}$ denotes the restriction of $S$'s domain 
to $V$ as follows: $S\,|_{V} = \{[\alpha\mapsto \tau]\,|\,\alpha\in V\}$.

We let notation $\sigma \sqsubseteq \rho$ 
denote that $\rho$ is an \emph{instance} of type scheme $\sigma$, and 
we define this relation as:
\begin{figure}[H] 
\[
  \infer[_{\{Inst\}}] 
        {\forall\,\overline{\alpha}\,.\,\rho\sqsubseteq [\overline{\alpha\mapsto\tau}]\rho} 
        {}
\]
  \centering 
  \caption{Type instantiation relation.}
  \label{fig:instantiation}
\end{figure} 
Another relation over types used in our formalization is 
\emph{subsumption}~\cite{PeytonJones2007}, written as $\sigma_{off} \leq \sigma_{req}$, 
which means that type $\sigma_{off}$ is at least as polymorphic 
as $\sigma_{req}$. This relation is necessary to deal 
correctly with type annotations.

\begin{figure}[H]
\[
  \begin{array}{ccc} 
    \infer[_{\{Skol\}}] 
          {\sigma \leq \forall\,\overline{\alpha}.\rho}
          {\overline{\alpha}\subseteq ftv(\sigma) & 
            \sigma \leq \rho}
    & 
    \infer[_{\{Spec\}}]
          {\forall\,\overline{\alpha}\,.\,\rho_1 \leq \rho_2} 
          {\overline{[\alpha\mapsto\tau]}\rho_1 \leq \rho_2}
    & 
    \infer[_{\{Mono\}}] 
          {\tau \leq \tau}
          {}
  \end{array}
\]
  \centering 
  \caption{Subsumption judgement.}
  \label{fig:subsumption}
\end{figure}

\section{Ambiguity and type improvement}

Type inference proceeds by collecting constraints generated 
by the use of defined function symbols and variables which 
are later solved. However, some constraints cannot be solved 
using defined instances due to have have what we call 
``unreachable type variables''. Given a qualified type 
$P \Rightarrow \tau$, we define the set of unreachable variables 
as $\ftv(P) - \ftv(\tau)$, i.e. variables occuring in predicates 
which do not appear in $\tau$. Such variables pose a problem 
since they cannot be further instantiated during type inference.
Haskell consider types containing unreachable variables as 
ambiguous and this was one of the main reasons behind the 
design of extensions like functional dependencies~\cite{Jones2000}
and type families~\cite{Chakravarty2005} which provides some additional 
constraint solving based on these additional specifications on 
class / instance definitions.

In this section, we review some concepts of the theory of 
qualified types like entailment and satisfiability to use then 
to define a type improvement strategy.

\subsection{Constraint entailment} 

A central problem in type systems of qualified types is determining 
when a restriction present on a type holds. The notion of 
constraint entailment is formalized by a relationship between 
sets of type constraints. In this report, we consider a definition of 
provability similar to that presented by Mark Jones~\cite{Jones1995}.
We say that a set of constraints $Q$ is provable from another set
of constraints $P$ using the information contained in the 
context $\Theta$ if it is possible to prove $\Theta ; P \Vdash Q$.
When $P = \emptyset$, we use notation $\Theta \Vdash Q$.

\begin{figure}[htb]
  \[
    \begin{array}{cccc}
      \infer[_{\{Mono\}}]
            {\Theta ; P \Vdash Q} 
            {Q \subseteq P} 
      & 
      \infer[_{\{Trans\}}]
            {\Theta ; P \Vdash Q} 
            {\Theta ; P \Vdash Q' 
             & 
             \Theta ; Q' \Vdash Q}
      & 
      \infer[_{\{Subst\}}]
            {\Theta ; S\,P \Vdash S\,Q}
            {\Theta ; P \Vdash Q} 
      & 
      \infer[_{\{Conj\}}]
            {\Theta ; P, Q \Vdash P', Q'}
            {\Theta ; P \Vdash P' & 
             \Theta ; Q \Vdash Q'} 
      \\ \\
      \multicolumn{4}{c}{
        \infer[_{\{Inst\}}]
              {\Theta ; P \Vdash \tau : C(\overline{\tau'}) }
              {\forall \overline{\alpha} .  P \Rightarrow \tau : C(\overline{\tau'}) \in \Theta^{ins}(C)}
      } 
      \\ \\
      \multicolumn{4}{c}{
        \infer[_{\{Super\}}]
              {\Theta ; P \Vdash \pi}
              {\Theta ; P \Vdash Q' & 
               \pi \in Q' &
               \pi = \alpha_1 : C(\overline{\alpha'_1}) & 
               \forall\overline{\alpha}. P \Rightarrow \alpha : C(\overline{\alpha}) \in \Theta^{cls}(C)} 
      }
    \end{array}
  \]
  \centering
  \caption{Constraint entailment.}
\end{figure}
The three first rules shows the requirements for an entailment 
relation: monotonicity, transitivity and closure under 
substitution~\cite{Jones1995}. Rule $Conj$ conjuncts two sets 
of constraints. Rule $Inst$ specifies that a constraint 
$\tau : C(\overline{\tau'})$ is entailed by a set $P$ if 
there's an instance 
$\forall \overline{\alpha} .  P \Rightarrow \tau : C(\overline{\tau'})$. 
Finally, rule $Super$ allows the entailment of a predicate 
by using super class information.

\subsection{Constraint satisfiability}

Using the entailment relation, we can define the concept of 
\emph{constraint satisfiability}. We say that a given set 
of constraints $P$ is satisfiable if there exists a substitution 
$S$ such that $\Theta \Vdash S\,P$ holds. Figure~\ref{fig:sat-algorithm} 
presents an algorithm which returns a set of substitutions 
which satisfy a given set of constraints in context $\Theta$. 
The algorithm is specified as a inductively defined judgement 
to deduce $\sats{P}{\mathbb{S}}{n}$, which 
depends on function $\mathtt{sat}$ which returns information 
about instances that satisfies a constraint $\pi$:

\[
  \begin{array}{lcl}
    \texttt{sat}(\Theta,\tau_1 : C(\overline{\tau})) & = & \left\{\begin{array}{l|l} 
                                (S|_{ftv(\tau)}, S\,P, \pi_0) & 
                                  \begin{array}{l}
                                    \forall\overline{\alpha} . P_0 \Rightarrow \pi_0 \in \Theta^{ins}(C) \\ 
                                    S_1 = [\overline{\alpha\mapsto\beta}],\:\:\overline{\beta}\:\mathtt{fresh}\\ 
                                    P \Rightarrow \tau'_1 : C(\overline{\tau'}) = S_1(P_0\Rightarrow \pi_0)\\ 
                                    S = \mgu(\tau_1, \tau'_1)\\
                                  \end{array}
                             \end{array}\right\}
  \end{array}
\]
We use a step counter on $\mathtt{sats}$ to ensure termination and let 
an empty set denote the failure of the satisfibility algorithm either 
by the step counter reaches zero or by not having any instance to 
satisfy the input constraints.

\begin{figure}[H] 
  \[
    \begin{array}{c}
      \infer[_{\{SFail\}}]
            {\sats{P}{\emptyset}{0}} 
            {}
      \\ \\ 
      \infer[_{\{SEmpty\}}]
            {\sats{\emptyset}{\id}{n}}
            {n > 0}
      \\ \\ 
      \infer[_{\{SConj\}}]
            {\sats{\pi , P}{\mathbb{S}}{n}} 
            {\begin{array}{l}
              n > 0\\
              \sats{\{\pi\}}{\mathbb{S}_0}{n - 1}\\
              \mathbb{S} = \{S'\circ S\,|\,S \in \mathbb{S}_0, \sats{S\,P}{\mathbb{S}_1}{n - 1}, S' \in \mathbb{S}_1\}
             \end{array}}
      \\ \\ 
      \infer[_{\{SInst\}}] 
            {\sats{\{\pi\}}{\mathbb{S}}{n}}
            {\begin{array}{l}
              n > 0 \\ 
              \Delta = \mathtt{sat}(\Theta,\pi)\\
              \mathbb{S} = \{S'\circ S\,|\,(S,Q,\pi')\in\Delta, \sats{Q}{\mathbb{S}_0}{n - 1}, S' \in \mathbb{S}_0\}
             \end{array}}
    \end{array}
  \]
  \caption{Constraint satisfiability.}
  \label{fig:sat-algorithm}
\end{figure}

\subsection{Context reduction} 

We name \emph{context reduction} the process of transforming 
each constraint $\pi$ to a new context $P$ introduced 
by the instance that has a head which matches with 
$\pi$. The reducing process continues until either $P = \emptyset$ 
or there's no further matching instances. Similarly to 
constraint satisfiability, we define a function to 
get information of about matching instances for a given 
input constraint.

\[
  \begin{array}{lcl}
    \mathtt{matches}(\pi,\Theta) & = &\{(S\,P,\pi')\,|\,(S,P,\pi') \in \mathtt{sat}(\Theta,[\overline{\alpha\mapsto K}]\,\pi)\}\\
                          &   &\mathtt{where} \\ 
                          &   &\:\:\:\:\overline{\alpha} = \mathtt{ftv}(\pi)\\
                          &   &\:\:\:\:\overline{K}\:\:\mathtt{are}\:\:\mathtt{new}\:\:\mathtt{Skolem}\:\:\mathtt{constants}
  \end{array}
\]

If we restrict ourselves to non-overlapping instances, 
$\mathtt{matches}$ always return a singleton or empty set for 
a given constraint. The context reduction for a given context
$Q = \{\pi_1,...,\pi_n\}$ is defined as: 

\begin{figure}[H] 
  \[
    \begin{array}{c}
      \infer[_{\{Red\}}]
            {\Theta \reduce \{\pi_1,...,\pi_n\} \leadsto Q_1,..., Q_n}
            {\begin{array}{l}
              \forall i. 1 \leq i \leq n \to Q_i = \left\{
                    \begin{array}{ll}
                      \pi_i & \Theta ; n_0\simp \pi_i \leadsto \bot \\
                      Q'_i & \Theta ; n_0 \simp \pi_i \leadsto Q'_i  
                    \end{array} 
                    \right. 
             \end{array}}
    \end{array}
  \]
  \centering 
  \caption{Context reduction.}
  \label{fig:context-reduction}
\end{figure}
Value $n_0$ denotes the initial ``fuel'' counter used to 
ensure termination of the reduction algorithm.

For each constraint in the input context, we use $\simp$ to 
simplify it, which could result in either in a failure (denoted 
by $\bot$) or in a new context $ Q'$. Note that the only reason for failures in 
simplification is when its step counter reaches zero.

\begin{figure}[H] 
  \[
    \begin{array}{cc}
      \infer[_{\{REmpty\}}]
            {\Theta ; n \simp \emptyset \leadsto \emptyset}
            {n > 0}
      & 
      \infer[_{\{RStop0\}}] 
            {\Theta ; 0 \simp Q \leadsto \bot} 
            {} 
      \\ \\ 
      \infer[_{\{RStop\}}]
            {\Theta ; n \simp \pi \leadsto \pi} 
            {\begin{array}{l}
              n > 0 \\
              \mathtt{matches}(\pi,\Theta) = \emptyset
             \end{array}}
      & 
      \infer[_{\{RConj1\}}]
            {\Theta ; n \simp \pi, Q \leadsto P, Q'}
            {\begin{array}{l}
              n > 0 \\ 
              \Theta ; n - 1 \simp \pi \leadsto P \\ 
              \Theta ; n - 1 \simp Q \leadsto Q'
             \end{array}}
      \\ \\ 
      \infer[_{\{RConj2\}}]
            {\Theta ; n \simp \pi, Q \leadsto \bot}
            {\begin{array}{l}
              n > 0 \\ 
              \Theta ; n - 1 \simp \pi \leadsto \bot \\ 
             \end{array}}
      & 
      \infer[_{\{RConj3\}}]
            {\Theta ; n \simp \pi, Q \leadsto \bot}
            {\begin{array}{l}
              n > 0 \\ 
              \Theta ; n - 1 \simp \pi \leadsto P \\ 
              \Theta ; n - 1 \simp Q \leadsto \bot 
             \end{array}}
      \\ \\
      \infer[_{\{RInst1\}}]
            {\Theta ; n \simp \pi \leadsto Q}
            {\begin{array}{l}
              n > 0 \\ 
              \{(P,\pi')\} = \mathtt{matches}(\pi,\Theta)\\
              \Theta;n - 1 \simp P \leadsto Q
             \end{array}}
      &
      \infer[_{\{RInst2\}}]
            {\Theta ; n \simp \pi \leadsto \bot}
            {\begin{array}{l}
              n > 0 \\ 
              \{(P,\pi')\} = \mathtt{matches}(\pi,\Theta)\\
              \Theta;n - 1 \simp P \leadsto \bot
             \end{array}}

    \end{array}
  \]
  \centering
  \caption{Reducing constraints.}
  \label{fig:reduce-constraints}
\end{figure}

\subsection{Type improvement}

Type improvement can be seen as a constraint simplification 
process which aims to eliminate ambiguities and infer more 
precise types. We follow~\cite{Jones1995} and use the concept 
of set of satisfying instances as a base for type improvement.
Given a constraint set $P$, we define the set of satisfying
instances for $P$ as $\lfloor P \rfloor = \{S\:P\,|\,\Theta\Vdash S\,P\}$. 
If $\Theta\Vdash S\,P$ holds, we say that the substitution $S$ 
satifies $P$ in $\Theta$. For any $S$, we have that 
$\lfloor S\,P\rfloor \subseteq\lfloor P \rfloor$. However, the 
inclusion $\lfloor P \rfloor \subseteq \lfloor S\,P\rfloor$ does not 
always hold but when it is true, we can  specialize 
$P$ to $S\,P$, which is a possibly simpler constraint set.

A possible target for improvement are contraints which 
have unreachable variables. If we can find a substitution 
$S$ that can satisfy these constraints, ambiguity is solved 
and we can produce a more acurate type. Rule $\impr$ formalizes 
this idea.

\begin{figure}[H]
  \[
    \infer[_{\{\mathtt{impr}\}}]
          {\Theta \impr \sigma \rhd \sigma'}
          {\begin{array}{cc}
            \sigma = \forall\overline{\alpha} . P \Rightarrow \tau & P_u = P - P\,|_{\ftv(\tau)} \\ 
            \Theta ; n_0 \vdash^{\mathtt{sats}} P_u \leadsto \{S\} & \overline{\alpha}_1 = \ftv(P\,|_{\ftv(\tau)} \Rightarrow \tau)\\
            \Theta \reduce P\,|^*_{\ftv(\tau)} \leadsto Q & \sigma' = \forall \overline{\alpha}_1 . Q\Rightarrow\tau\\ 
           \end{array}}
  \]
  \centering 
  \caption{Type improvement.}
  \label{fig:impr}
\end{figure}
 Notation $P\,|^*_{V}$ denotes the 
set of type class constraints in $P$ that has reachable variables 
from $V$. It is defined as: 
\begin{figure}[H]
  \[
    \begin{array}{lcl} 
      P\,|_{V} & = & \{\tau : C\overline{\tau'} \in P\,|\,\ftv(\tau) \cap V \neq \emptyset\}\\
      P\,|^{*}_{V} & = & \left\{
                  \begin{array}{ll}
                    P\,|_{V} & \mathtt{if}\:\ftv(P\,|_{V}) \subseteq V \\ 
                    P\,|^{*}_{\ftv(P\,|_{V})} & \mathtt{otherwise}\\
                  \end{array}
                   \right.
    \end{array} 
  \]
  \caption{Constraints with reachable type variables.}
  \label{fig:constrreach}
\end{figure}
Improvement starts by determining the set of constraints which 
has only unreachable type variables and then runs the constraint 
satisfiability algorithm on the set of constraints which has 
unreachable variables aiming to find a unique solution to them. 
The final type scheme is built from the reduced constraints with 
reachable variables and the simple type $\tau$.


\section{Type system definition}

\subsection{Typing rules for expressions} 

We define expression typing by the following judgement 

\[
  \Theta\,|\,\Gamma \typing{exp} e_s \leadsto \langle e_t : \rho, \Theta' , \Gamma' \rangle  
\]
where $\Theta$ denotes the global definition environment which 
holds information about class / instance declarations, 
data type and  function definitions; and $\Gamma$ is 
the typing environment, which holds type information for 
all variables, functions and data type constructor currently 
in scope. The expression judgement can modify the 
global definition and typing environments due to the 
desugaring of $\lambda$-expressions. When a rule does not change 
the environments, we use the following simplified version 
of the expression judgement:

\[
  \Theta\,|\,\Gamma \typing{exp} e_s \leadsto e_t : \rho
\]
We start presenting typing rules for basic expressions 
(Figure~\ref{fig:typingexpr01})

\begin{figure}[H] 
  \[
    \begin{array}{cc}
      \infer[_{\{Lit\}}]
            {\Theta\,|\,\Gamma\typing{exp} w \leadsto w : \word}
            {}
      & 
      \infer[_{\{Var1\}}]
            {\Theta\,|\,\Gamma\typing{exp} v \leadsto v : \rho} 
            {\Gamma(v) = \sigma & \sigma \sqsubseteq \rho & \Theta_U(v) = \bot} 
      \\ \\
      \infer[_{\{Varf\}}]
            {\Theta\,|\,\Gamma\typing{exp} v \leadsto D : \rho} 
            {\begin{array}{cr} 
              \multicolumn{2}{c}{
                \Theta_U(v) = \mathtt{data}\:T(\alpha_{args},\alpha_{ret}) \mathtt{=} D
              } 
              \\ 
              \Gamma(D) = \sigma 
              & 
              \sigma \sqsubseteq \rho
             \end{array}} 
      &
      \infer[_{\{Con\}}]
            {\Theta\,|\,\Gamma\typing{exp} D(e_1,...,e_n) \leadsto D(e'_1,...,e'_n) : \rho}
            {\begin{array}{cc} 
               \Gamma(D) = \sigma
               & 
               \sigma \inst \tau_1 \times ... \times \tau_n \to \tau
               \\ 
               \multicolumn{2}{c}{
                 \forall i. 1 \leq i \leq n \to \Theta\,|\,\Gamma\typing{exp} e_i \leadsto e'_i : P_i \Rightarrow \tau_i 
               }
               \\ 
               \multicolumn{2}{c}{
                 \rho = \left(\bigcup_{1 \leq i \leq n} P_i\right)\Rightarrow \tau
               }
             \end{array}}
    \end{array}
  \]    
  \caption{Expressions, part 01.} 
  \label{fig:typingexpr01}
\end{figure}
Rule $\{Lit\}$ specifies that literals have type $\word$. For variables,
we have two distinct cases: 1) for variables which are defined function 
references, which are desugared to the function unique type data 
constructor and 2) for normal variables which are desugared to themselves.
Rule for data constructors just checks that each argument expression has 
the required argument type.

\begin{figure}[htb] 
  \[
    \begin{array}{cc}
      \infer[_{\{FieldAcc\}}] 
            {\Theta\,|\,\Gamma \typing{exp} e.v \leadsto e'.v : \tau}
            {\Theta\,|\,\Gamma\typing{exp} e \leadsto e' : T(\tau_1,...,\tau_n) & 
             \Theta_X(T) = \Gamma_f & 
             \Gamma_f(v) = \tau}
      &
      \infer[_{\{Ann\}}] 
            {\Theta\,|\,\Gamma \typing{exp} e : \sigma \leadsto e' : \sigma} 
            {\Theta\,|\,\Gamma\typing{exp} e \leadsto e' : \sigma'
             & 
             \sigma' \leq \sigma}
    \end{array}
  \]
  \caption{Expressions, part 02.}
  \label{fig:typingexpr02}
\end{figure}
Rule $FieldAcc$ shows how to type and desugar a field access 
expression: we start by checking that expression $e$ has a 
contract type $T(\tau_1,...,\tau_n)$ and then we check that 
type $T$ does have a field named $v$ and return its type.
We check type annotated expressions by infering its type, $\sigma'$, 
and then check if it is as least as polymorphic as $\sigma$ 
(Figure~\ref{fig:subsumption}). 

\begin{figure}[H] 
  \[
    \begin{array}{c}
      \infer[_{\{CallD\}}] 
            {\Theta\,|\,\Gamma\typing{exp} f(e_1,...,e_n) \leadsto f(e'_1,...,e'_n) : \rho}
            {\begin{array}{cc} 
              f \in \dom{\Theta_U} & \Gamma(f) = \sigma \\
               \multicolumn{2}{c}{
                  \sigma \sqsubseteq P \Rightarrow \tau_1 \times ... \times \tau_n \to \tau 
               }\\ 
               \multicolumn{2}{c}{
                 \forall i. 1 \leq i \leq n \to \Theta\,|\,\Gamma\typing{exp} e_i \leadsto e'_i : P_i \Rightarrow \tau_i
               }\\ 
               \multicolumn{2}{c}{
                 \rho = \left(\{P\}\cup \bigcup_{1 \leq i \leq n} P_i\right) \Rightarrow \tau 
               }
             \end{array}}
      \\ \\ 
      \infer[_{\{CallI\}}] 
            {\Theta\,|\,\Gamma \typing{exp} f(e_1,...,e_n) \leadsto \invoke(f,(e_1,...,e_n)) : \rho}
            {\begin{array}{cc}
              f \not\in \dom{\Theta_U(f)} & \Gamma(f) = T(\alpha_1,...,\alpha_n) \\ 
               \multicolumn{2}{c}{
                 \forall i. 1 \leq i \leq n \to \Theta\,|\,\Gamma \typing{exp} e_i \leadsto e'_i : P_i \Rightarrow \tau_i 
               }\\ 
               \multicolumn{2}{c}{
                 \pi = T(\tau_1 ,... ,\tau_n)\,:\,\invokable(\tau_1 ,... ,\tau_n)
               }\\
               \multicolumn{2}{c}{
                 \rho = \left(\{\pi\} \cup \bigcup_{1\leq i \leq n} P_i \right)\Rightarrow \tau_{ret}
               }
             \end{array}}
    \end{array}
  \]
  \centering 
  \caption{Expressions, part 03.} 
\end{figure}
Next, we present the rules for dealing with function calls. The first rule 
deals with direct calls, which are typed as expected: first we get function 
type and instantiate it and check if its parameter types matches the arguments 
types. Finally, we say that the call type is the qualified type formed by 
set of predicates of arguments and the function type itself together with 
the function return's type. The desugaring of a direct call is just the 
same call with its desugared arguments. 
Typing indirect calls follows the same strategy for direct ones. The main 
difference is that it desugars to a call to $\invoke$ function.

Now, we turn our attention to how to deal with $\lambda$-expressions: 
we type the body using as additional assumptions the $\lambda$-expression arguments 
with its types. Next, we apply a closure conversion step over the 
$\lambda$'s type and body to produce:

\begin{itemize}
  \item A value of the type representing the abstraction, which can be either 
    a closure or the constructor of the unique type for the $\lambda$'s generated 
    function. 
  \item Modified environments containing both the $\lambda$'s generated function, 
    unique type and $\invokable$ instances.
\end{itemize} 

\begin{figure}[htb]
  \[
    \begin{array}{c}
      \infer[_{\{Lam\}}]
            {\Theta\,|\,\Gamma\typing{exp}\mathtt{lam}\,(x_1 : \tau_1,...,x_n : \tau_n)\:body \leadsto \langle D, \rho , \Theta', \Gamma' \rangle } 
            {\begin{array}{c}
              \Theta\,|\,\Gamma,x_1:\tau_1,...,x_n:\tau_n\typing{body} body \leadsto \langle body', P' \Rightarrow \tau', \Theta_1, \Gamma_1\rangle\\
              \Theta;\Gamma; (P' \Rightarrow x_1 : \tau_1\times ... \times x_n : \tau_n \to \tau'); body' \overset{cc}{\leadsto} \langle D, \rho, \Theta', \Gamma'\rangle\\ 
             \end{array}}
    \end{array}
  \]
  \centering
  \caption{Expressions, part 04.}
\end{figure}

\section{Typing rules for statements}

\section{Typing rules for declarations}

\section{Desugaring}\label{sec:desugar} 

In this section we describe the desugaring steps performed by new 
Solidity implementation.

The desugaring of abstractions is done by $\overset{cc}{\leadsto}$ predicate (Figure~\ref{fig:closurepred}), 
which has two rules. The first rule, $NC$, deal with the abstractions which does not 
have free program variables (no closure needed): we simply generate its 
function declaration, corresponding unique type and $\invokable$ instance. Each of these 
tasks are done by a specific rule, presented next. 

\begin{figure}[H]
  \[
    \begin{array}{c}
      \infer[_{\{NC\}}]
            {\Theta;\Gamma;(P \Rightarrow x_1 : \tau_1\times ... \times x_n : \tau_n \to \tau_r); body \cc \langle D, \rho, \Theta', \Gamma' \rangle}
            {\begin{array}{c}
              \fpv(body) - \{x_1, ...,x_n \} = \emptyset\\
              P \Rightarrow \tau_1\times ... \times \tau_n \to \tau_r \sig \langle sig, f, \forall \overline{\alpha} . \rho \rangle\\ 
              f ; \forall \overline{\alpha}. \rho \unique \mathtt{data}\:T(\overline{\alpha}) = D\\
              sig ; \mathtt{data}\:T(\overline{\alpha}) = D \geninvoke instd\\ 
              \Gamma' = \Gamma, f : \forall\overline{\alpha}.\rho, D : \forall\overline{\alpha} . T(\overline{\alpha})\\
              \Theta' = \Theta [\invokable \mapsto^i instdecl]
             \end{array}}
 \\ \\
      \infer[_{\{CC\}}]
            {\Theta;\Gamma;(P \Rightarrow \tau_1\times ... \times \tau_n \to \tau); body \cc \langle D, \rho, \Theta', \Gamma' \rangle}
            {\begin{array}{c}
              \fpv(body) - \dom{\Gamma} = \{x'_1 : \tau_1\}\\ 
              \fpv(body) - \dom{\Gamma} \closuretype \mathtt{data}\:T(\alpha_1,...,\alpha_n) = D_{clo}(\tau_1,...,\tau_m)\\  
              \{f\}\cup \{x_1, ..., x_n\}\text{ are fresh names} \\
             \end{array}}
    \end{array}
  \]
  \centering
  \caption{Desugaring of $\lambda$-expressions.}
  \label{fig:closurepred}
\end{figure}

The generation of function signatures for $\lambda$-abstraction are as follows: first 
we generate the quantified type, $\sigma$, for $\lambda$ expression. Using the 
set of argument types, we create fresh argument variable names to create the 
newly defined function arguments. The signature is produced using the 
infered predicates, a fresh function name, the set of arguments and its 
return type. Note that we demand that predicates produced should be entailed 
by current global context $\Theta$.
\begin{figure}[H]
  \[
    \begin{array}{c}
      \infer[_{\{Sig\}}]
            {
             P \Rightarrow \tau_1 \times ... \times \tau_n \to \tau_r \sig 
             \langle \forall\overline{\alpha}\,P' . \mathtt{function }f (x_1 : \tau_1,...,x_n : \tau_n) \to \tau_r, \sigma\rangle
            }
            {
              \begin{array}{c}
                 \overline{\alpha} = ftv(P \Rightarrow \tau_1 \times ... \tau_n \to \tau_r) - ftv(\Gamma)\\ 
                 \text{f is a fresh function name}\\
                 x_1, ... , x_n \text{ are fresh argument names}\\
                 \sigma = \forall\overline{\alpha}. P \Rightarrow \tau_1 \times ... \times \tau_n \to \tau_r \:\:\:\:\:\:\:
                 \Theta ; P \Vdash P'
              \end{array}
            }
    \end{array}
  \]
  \caption{Generation of $\lambda$-function signatures.}
  \label{fig:genlambdasig} 
\end{figure}

Generation of unique data type for a function using its type information. 
Basically, the judgement $\unique$ just creates fresh names for the
type and data constructor. The generated type will use the type variables 
for the function infered type as its arguments.

\begin{figure}[H] 
  \[
    \begin{array}{c}
      \infer[_{\{unique\}}] 
            {f ; \forall \overline{\alpha}. \rho \unique \mathtt{data}\:T(\overline{\alpha}) = D}
            {f, T, D \text{ are fresh names}}
    \end{array} 
  \]
  \caption{Generation of unique types for functions.}
  \label{fig:genuniquetype}
\end{figure}
Next, we turn our attention to $\invokable$ instance generation, using rule 
$\geninvoke$. The rule starts by generating the $\invoke$ function body which
is formed by a call to function $f$, that triggered the instance creation, 
using a pattern matching over the unique / closure type and a tuple of $f$'s 
input arguments. The main type for the instance create is the unique / closure 
type and the weak arguments are just the tuple formed by $f$'s argument and 
return types.

\begin{figure}[htb]
  \[
    \begin{array}{c}
      \infer[_{\{Gen\}}]
            {\forall\,\overline{\alpha}\, P . \mathtt{function}\:f (x_1 : \tau_1,...,x_n : \tau_n) \to \tau_r ; \mathtt{data}\:T(\overline{\alpha'}) = D(\overline{\tau})\geninvoke instd}
            {\begin{array}{c} 
              body = \mathtt{match}\:(self, args)\:\mathtt{with}\:(D(pat_1,...,pat_m), (pat'_1,...,pat'_n)) \Rightarrow \\ 
              \:\:\:\:\mathtt{return}\:f((pat_1,...,pat_m), pat'_1,...,pat'_n) \\
              fundecl = \mathtt{function}\:\invoke (self : T(\overline{\tau}), args : \tau_1 \times ... \times \tau_n) \to \tau_r \:body \\
              instd = \forall\overline{\alpha} P . \mathtt{instance}\:T(\overline{\tau}):\invokable(\overline{\tau})\:fundecl\\
             \end{array}}
    \end{array}
  \]
  \caption{Generation of $\invokable$ instances for functions.} 
  \label{fig:geninvokable} 
\end{figure}

\section{Conclusions and Future Work}

From our experiments we can conclude that~\cite{Faxen2002}.

\bibliographystyle{abbrv}
\bibliography{references}  
\end{document}
